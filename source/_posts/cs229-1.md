---
title: CS229 lesson 1 Supervised Learning Setup. Linear Regression.
tags:
  - CS229
  - machine learning
categories:
  - machine learning
date: 2018-11-07 21:04:54
mathjax: true
---

前言
===========
+ 主要结合李航的《统计学习方法》进行学习
+ 只摘录关键知识点，不做详细笔记，仅为方便日后复习有个方向
+ 学习: 如果一个系统能够通过执行某个过程改进它的性能，这就是学习。 --- Herbert A. Simon

统计学习
===========
+ 统计学习的特点，对象，目的，方法，研究

## 监督学习
+ 由训练资料中学到或建立一个模式（函数 / learning model），并依此模式推测新的实例。
+ 基本概念：input space, output space, feature space
+ 其它名词：instance, feature vector, 联合概率分布
+ 假设空间: $ \mathcal{F} = \\{ f\;|  \mathit{Y} = f(X) \\} $
+ 最终变成求 $\min\limits_{f\in\mathcal{F}}R_{emp}(f)$ 或 $min_{f\in\mathcal{F}}R_{srm}(f)$ 的问题

## 统计学习三要素
+ 方法 = 模型 + 策略 + 算法

### 策略
+ 损失函数: 0-1, quadratic, absolute, logarithmic
+ 风险函数(期望损失): $ R_{exp}(f) = E_{p}[L(Y, f(X))] = \int_{x\times y}L(y, f(x))P(x,y)dxdy $
+ 经验风险(经验损失)(empirical loss): $\displaystyle R_{emp}(f) = \frac{1}{N}\sum_{i=1}^{N}L(y_i, f(x_i)) $
+ 根据大数定理, 可用$R_{emp}(f)$估计$R_{exp}(f)$, 但由于现实中样本有限, 甚至很少，所以需要矫正$R_{emp}(f)$
+ 经验风险最小化(ERM)和结构风险最小化(SRM)
  + ERM: 用最优化方法求解$\min\limits_{f\in\mathcal{F}}R_{emp}(f)$
    + 样本容量很小时容易过拟合(over-fitting), 但样本容量大时，学习效果很好
    + 当模型是条件概率分布，损失函数是对数损失函数时，经验风险最小化就等价于极大似然估计(MLE)([证明](http://datahonor.com/2017/03/03/最大似然估计与经验风险最小化/)). 
  + SRM: 等价于正则化(regularizer), 即求 $\min\limits_{f\in\mathcal{F}}R_{srm}(f)$
    + 结构风险: $\displaystyle R_{srm}(f) = R_{emp}(f) + \lambda J(f)$ 
      + 其中 $\lambda J(f)$ 位正则化项或罚项(penalty term)
      + $J(f)$是模型空间复杂度, 为定义在$\mathcal{F}$上的泛函. $f$越复杂, $J(f)$越大.
      + $\lambda \ge 0$是系数, 用以权衡经验风险和模型复杂度
      + $R_{srm}(f)$小要求$R_{emp}(f)$和$J(f)$同时小, $R_{srm}(f)$小的模型往往对训练数据以及未知的测试数据都有较好的预测
      + 当模型是条件概率分布, 损失函数是对数损失函数, 模型复杂度由模型的先验概率分布表示时，结构风险最小化就等价于最大后验概率估计(MAP)(证明)

## 模型评估与选择
+ 训练误差(tranning error): 模型关于训练数据集的平均损失
+ 测试误差(test error): 模型关于测试数据集的平均损失, 反映了模型的预测能力(泛化能力 generalization ability)
+ 过拟合: 所选模型参数过多, 对训练数据预测的很好, 对测试数据预测的很差
+ 模型选择时要选择复杂度适当的模型, 防止过拟合.

## 正则化与交叉验证
+ 此为常用的两种模型选择方法

### 正则化
+ $\min\limits_{f\in\mathcal{F}}R_{srm}(f)$
+ 正则化项: 一般是模型复杂度的单调递增函数，模型越复杂，正则化值越大
> 如参数向量$w$的$L_1$范数$||w_1||$或$L_2$范数$\frac{1}{2}||w_1||^2$
+ 模型越复杂, 先验概率越大

### 交叉验证
+ 样本充足时, 可随机切成训练集(用于训练模型), 验证集(用于模型选择, 选择预测误差最小的模型)和测试集(模型评估)
+ 交叉验证: 重复使用数据, 反复切, 反复训练, 测试及模型选择
+ 简单交叉验证: 随机切成训练集和测试集, 选测试误差最小的模型
+ $S$折交叉验证(S-fold cross validation): 切成$S$份, 每次选$S-1$份训练, $1$份测试, 重复$S$次
+ 留一交叉验证: $S=N$, 数据集为$N$, 数据集较少时用

## 泛化能力
+ 即模型$\hat{f}$的预测能力, 用$R_{exp}(\hat{f})$来表示
+ 泛化误差上界: $R(f) \le \hat{R}(f) + \epsilon(d, N, \delta)$
> $R(f)$为泛化误差
> $\le$右边为泛化误差上界
> $\hat{R}(f)$为训练误差
> $\epsilon(d, N, \delta) = \sqrt{\frac{1}{2N}(\log d + \log \frac{1}{\delta})}$
+ 训练误差小的模型, 泛化误差也会小

## 生成模型与判别模型
+ 监督学习的方法可以分为: 生成方法(generative approach)和判别方法(discriminative approach)



